# Project Summary: Akasa Air Data Engineering Task

## Overview
This is a complete, production-ready data engineering solution that successfully implements all requirements specified in the task.

## âœ… Requirements Met

### 1. Dual Processing Approaches
- âœ… **SQL-based (MySQL + SQLAlchemy ORM)**: Complete implementation with optimized queries
- âœ… **In-memory (Pandas)**: Full DataFrame-based processing pipeline

### 2. Data Sources
- âœ… **CSV**: Customer data parsing with validation
- âœ… **XML**: Orders data parsing with comprehensive error handling

### 3. Data Cleaning & Quality
- âœ… Date normalization (handles 12+ date formats)
- âœ… Mobile number validation and cleaning
- âœ… Missing value handling
- âœ… Type conversion and validation
- âœ… Comprehensive error logging

### 4. KPIs Implemented
All 4 KPIs fully implemented in both SQL and Pandas:

1. **Repeat Customers** - Customers with > 1 order
2. **Monthly Order Trends** - Orders and revenue per month
3. **Regional Revenue** - Revenue breakdown by region
4. **Top Spenders (30 Days)** - Top 10 customers by recent spend

### 5. Database Design
- âœ… Proper SQLAlchemy models (Customer, Order)
- âœ… Indexes on frequently queried columns
- âœ… Connection pooling
- âœ… Transaction management
- âœ… No SQL injection vulnerabilities (ORM-based)

### 6. Security & Best Practices
- âœ… Environment variables for credentials (.env)
- âœ… No hardcoded passwords
- âœ… .gitignore for sensitive files
- âœ… Parameterized queries via ORM

### 7. Code Quality
- âœ… PEP 8 compliant
- âœ… Type hints throughout
- âœ… Comprehensive docstrings
- âœ… Modular, reusable functions
- âœ… Separation of concerns

### 8. Logging & Error Handling
- âœ… Centralized logging system
- âœ… Data quality issue tracking
- âœ… Graceful error handling
- âœ… Structured error messages

### 9. Documentation
- âœ… Detailed README.md
- âœ… Quick Start Guide
- âœ… API documentation in docstrings
- âœ… Example outputs
- âœ… Troubleshooting guide

### 10. Deliverables
- âœ… Working code (both SQL and Pandas)
- âœ… Requirements.txt
- âœ… .env.example
- âœ… Sample data files
- âœ… Complete documentation

## ğŸ“ Project Structure

```
AkasaAir-DataEngineer-Task1/
â”œâ”€â”€ README.md                    # Comprehensive documentation
â”œâ”€â”€ QUICKSTART.md                # 5-minute setup guide
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ .gitignore                   # Security & cleanup
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ customers.csv           # Sample customer data
â”‚   â””â”€â”€ orders.xml              # Sample orders data
â”œâ”€â”€ outputs/                     # Generated KPI results
â””â”€â”€ src/
    â”œâ”€â”€ main.py                 # Main entry point
    â”œâ”€â”€ config/
    â”‚   â””â”€â”€ config.py           # Configuration management
    â”œâ”€â”€ database/
    â”‚   â”œâ”€â”€ db_setup.py         # SQLAlchemy models
    â”‚   â””â”€â”€ load_data.py        # CSV/XML data loading
    â”œâ”€â”€ processing/
    â”‚   â”œâ”€â”€ sql_queries.py      # SQL-based KPIs
    â”‚   â””â”€â”€ pandas_processing.py # Pandas-based KPIs
    â””â”€â”€ utils/
        â”œâ”€â”€ logger.py           # Logging system
        â””â”€â”€ helpers.py          # Data cleaning utilities
```

## ğŸ¯ Key Features

1. **Automated Pipeline**: Single command execution (`python -m src.main`)
2. **Dual Validation**: Compare SQL vs Pandas results
3. **Production Ready**: Error handling, logging, security
4. **Extensible**: Easy to add new KPIs or data sources
5. **Well-Documented**: Clear code with comprehensive docs

## ğŸ“Š Sample Data

- **20 Customers** across 4 regions (North, South, East, West)
- **28 Orders** spanning September-November 2024
- **5 SKUs** with varying prices
- Realistic order patterns with repeat customers

## ğŸš€ Running the Application

```bash
# 1. Setup
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# 2. Configure
cp .env.example .env
# Edit .env with your MySQL credentials

# 3. Run
python -m src.main
```

## ğŸ“ˆ Output Files Generated

**SQL Approach (JSON)**:
- sql_repeat_customers.json
- sql_monthly_trends.json
- sql_regional_revenue.json
- sql_top_spenders.json

**Pandas Approach (CSV)**:
- pandas_repeat_customers.csv
- pandas_monthly_trends.csv
- pandas_regional_revenue.csv
- pandas_top_spenders.csv

## ğŸ” Code Highlights

### Data Cleaning Example
```python
def normalize_date(date_value):
    """Handles 12+ date formats automatically"""
    # Tries multiple formats, returns datetime or None
    
def normalize_mobile_number(mobile):
    """Cleans and validates mobile numbers"""
    # Removes special chars, validates length
```

### SQL Query Example
```python
def get_repeat_customers(self):
    """SQL-based approach with JOIN and GROUP BY"""
    query = session.query(
        Customer, func.count(Order.order_id)
    ).join(Order).group_by(Customer).having(
        func.count(Order.order_id) > 1
    )
```

### Pandas Processing Example
```python
def get_repeat_customers(self):
    """Pandas-based approach with groupby and merge"""
    order_counts = df_orders.groupby('mobile_number').size()
    repeat_customers = df_customers.merge(order_counts)
```

## ğŸ›¡ï¸ Security Features

- Environment variable management
- No SQL injection (ORM-based)
- Secure credential handling
- .gitignore for sensitive files

## ğŸ“š Technologies Used

- **Python 3.8+**: Core language
- **MySQL**: Relational database
- **SQLAlchemy 2.0**: ORM and query builder
- **Pandas**: Data manipulation
- **PyMySQL**: MySQL connector
- **python-dotenv**: Environment management
- **lxml**: XML parsing
- **tabulate**: Result formatting

## âœ¨ Production Considerations

The code includes:
- Connection pooling for database efficiency
- Indexes on frequently queried columns
- Transaction management for data integrity
- Comprehensive error handling
- Structured logging for debugging
- Type safety with type hints
- Modular design for maintainability

## ğŸ“ Learning Outcomes

This project demonstrates:
1. ETL pipeline design
2. Multi-source data integration (CSV/XML)
3. Dual processing approaches (SQL vs Pandas)
4. Data quality management
5. Production-ready coding practices
6. Clean architecture principles

---

**Status**: âœ… Complete and ready for review
**Date**: November 2024
**Version**: 1.0.0
